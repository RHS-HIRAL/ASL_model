{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7RQCs9QhgXe"
   },
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jd3uRIn3h2Gw"
   },
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Paths (adjust to your folder structure)\n",
    "DRIVE_BASE = '/content/drive/MyDrive/asl_model_train/'\n",
    "TRAIN_H5 = os.path.join(DRIVE_BASE, 'train_data.h5')\n",
    "VAL_H5   = os.path.join(DRIVE_BASE, 'val_data.h5')\n",
    "CHECKPOINT_DIR = os.path.join(DRIVE_BASE, 'checkpoints')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "BEST_MODEL_PATH   = os.path.join(CHECKPOINT_DIR, 'model_best.h5')\n",
    "LATEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'model_latest.h5')\n",
    "EPOCH_FILE        = os.path.join(CHECKPOINT_DIR, 'epoch.txt')\n",
    "LOG_CSV           = os.path.join(CHECKPOINT_DIR, 'training_log.csv')\n",
    "\n",
    "# 3Ô∏è‚É£ Hyper‚Äëparameters\n",
    "SEQ_LEN     = 300      # match how you preprocessed\n",
    "FEATURE_DIM = 126\n",
    "NUM_CLASSES = 1000\n",
    "BATCH_SIZE  = 25\n",
    "EPOCHS      = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCIjfWhqh_-R"
   },
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ (Optional) TPU strategy\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"‚ö° TPU enabled\")\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"‚öôÔ∏è CPU/GPU strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWPZrb5PiCmJ"
   },
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Data generator\n",
    "def data_generator(h5_path, batch_size):\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        X, y = f['X'], f['y']\n",
    "        size = len(X)\n",
    "        while True:\n",
    "            idxs = np.arange(size)\n",
    "            np.random.shuffle(idxs)\n",
    "            for start in range(0, size, batch_size):\n",
    "                batch = idxs[start:start+batch_size]\n",
    "                yield X[batch], y[batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lmyoKgPjQNa"
   },
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Model builder (inside strategy scope)\n",
    "with strategy.scope():\n",
    "    def build_model(seq_len, feature_dim, num_classes):\n",
    "        m = Sequential([\n",
    "            Masking(mask_value=0., input_shape=(seq_len, feature_dim)),\n",
    "            LSTM(64, return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        m.compile(optimizer=Adam(1e-3),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        return m\n",
    "\n",
    "    # 7Ô∏è‚É£ Resume logic\n",
    "    if os.path.exists(LATEST_MODEL_PATH):\n",
    "        print(\"üîÑ Resuming from last checkpoint‚Ä¶\")\n",
    "        model = tf.keras.models.load_model(LATEST_MODEL_PATH)\n",
    "        # read last epoch (stored as completed epochs)\n",
    "        with open(EPOCH_FILE, 'r') as f:\n",
    "            initial_epoch = int(f.read().strip())\n",
    "    else:\n",
    "        print(\"üöÄ Starting new training run\")\n",
    "        model = build_model(SEQ_LEN, FEATURE_DIM, NUM_CLASSES)\n",
    "        initial_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ Compute steps\n",
    "with h5py.File(TRAIN_H5, 'r') as f: train_size = len(f['X'])\n",
    "with h5py.File(VAL_H5,   'r') as f: val_size   = len(f['X'])\n",
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "val_steps       = val_size   // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ Callbacks\n",
    "checkpoint_latest = ModelCheckpoint(\n",
    "    LATEST_MODEL_PATH, save_best_only=False, verbose=1\n",
    ")\n",
    "checkpoint_best = ModelCheckpoint(\n",
    "    BEST_MODEL_PATH, save_best_only=True,\n",
    "    monitor='val_accuracy', mode='max', verbose=1\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True\n",
    ")\n",
    "csv_logger = CSVLogger(LOG_CSV, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochTracker(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # save next starting epoch\n",
    "        with open(EPOCH_FILE, 'w') as f:\n",
    "            f.write(str(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05QJdbXzhZc5"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    checkpoint_latest,\n",
    "    checkpoint_best,\n",
    "    early_stop,\n",
    "    csv_logger,\n",
    "    EpochTracker()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü Launch Training\n",
    "history = model.fit(\n",
    "    data_generator(TRAIN_H5, BATCH_SIZE),\n",
    "    validation_data=data_generator(VAL_H5, BATCH_SIZE),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=EPOCHS,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOAVfs0FIs3NnimPt+BO388",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
